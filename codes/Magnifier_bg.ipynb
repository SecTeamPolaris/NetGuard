{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "urls_dict = np.load(\"../data/features_A.npy\", allow_pickle=True).item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.e ** -(x-20))\n",
    "\n",
    "#IDF\n",
    "import math\n",
    "urls_sta = {}\n",
    "urls_all_count = 0\n",
    "url_max_depth = 0\n",
    "for device in list(urls_dict.keys()):\n",
    "    for url_tuple in urls_dict[device]:\n",
    "        if url_tuple[0] not in list(urls_sta.keys()):\n",
    "            urls_sta[url_tuple[0]] = 0\n",
    "        urls_sta[url_tuple[0]] += url_tuple[1]\n",
    "        urls_all_count += url_tuple[1]\n",
    "\n",
    "        if len(url_tuple[0].split('.'))-1 > url_max_depth:\n",
    "            url_max_depth = len(url_tuple[0].split('.'))-1\n",
    "\n",
    "#split urls by domain level\n",
    "# urls_domain_level_dict = {}\n",
    "# urls_all_count_dm = 0\n",
    "# for i in range(1,url_max_depth+1):\n",
    "#     # url_tmp_dict = {}\n",
    "#     for url in list(urls_sta.keys()):\n",
    "#         if len(url.split('.'))-1 < i :\n",
    "#             continue\n",
    "#         url_split = '.'.join(url.split('.')[-i-1:])\n",
    "#         if url_split not in list(urls_domain_level_dict.keys()):\n",
    "#             urls_domain_level_dict[url_split] = 0\n",
    "#         # accumulate urls with same dm lv\n",
    "#         urls_domain_level_dict[url_split] += urls_sta[url]\n",
    "#         urls_all_count_dm += urls_sta[url]\n",
    "\n",
    "\n",
    "# another option: tfidf with urls (no split)\n",
    "urls_domain_level_dict = {}\n",
    "urls_all_count_dm = 0\n",
    "for url in list(urls_sta.keys()):\n",
    "    if url not in list(urls_domain_level_dict.keys()):\n",
    "        urls_domain_level_dict[url] = 0\n",
    "    urls_domain_level_dict[url] += urls_sta[url]\n",
    "    urls_all_count_dm += urls_sta[url]\n",
    "    \n",
    "\n",
    "urls_idf = {}\n",
    "for url in list(urls_domain_level_dict.keys()):\n",
    "    urls_idf[url] = math.log(urls_all_count_dm / urls_domain_level_dict[url])\n",
    "\n",
    "# sigmoid版本的tf_idf\n",
    "urls_tfidf_dict = {}\n",
    "idf_dict = {}\n",
    "for device in urls_dict:\n",
    "    if device not in urls_tfidf_dict:\n",
    "        urls_tfidf_dict[device] = []\n",
    "    # 统计url总数\n",
    "    count = np.array([item[1] for item in urls_dict[device]]).sum()\n",
    "    # (url, url in device, url not in device)\n",
    "    urls_device_count_list = [(item[0], item[1], urls_domain_level_dict[item[0]] - item[1]) for item in urls_dict[device]]\n",
    "\n",
    "    idf = [(item[0], item[1], sigmoid(urls_all_count_dm / (item[2] + 1))) for item in urls_device_count_list ]\n",
    "    idf_dict[device] = idf\n",
    "    tfidf_std_list = [(item[0], item[1], item[1]/count * sigmoid(urls_all_count_dm / (item[2] + 1)))  for item in urls_device_count_list]\n",
    "\n",
    "    # 归一化\n",
    "    tf_sum = np.array([item[2] for item in tfidf_std_list]).sum()\n",
    "    tfidf_std_list = [(item[0], item[1], item[2]/tf_sum) for item in tfidf_std_list]\n",
    "    # tfidf_std_list = [(item[0], item[1], item[1]/count) for item in tfidf_list]\n",
    "\n",
    "    urls_tfidf_dict[device]  = tfidf_std_list\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 计算每一个url的tf_idf\n",
    "# urls_tfidf_dict = {}\n",
    "# for device in urls_dict:\n",
    "#     if device not in urls_tfidf_dict:\n",
    "#         urls_tfidf_dict[device] = []\n",
    "#     # 统计url总数\n",
    "#     count = np.array([item[1] for item in urls_dict[device]]).sum()\n",
    "#     # 计算 tfidf\n",
    "#     tfidf_list = [(item[0], item[1], item[1]/count*urls_idf[item[0]]) for item in urls_dict[device]]\n",
    "#     # 归一化\n",
    "#     tf_sum = np.array([item[2] for item in tfidf_list]).sum()\n",
    "#     tfidf_std_list = [(item[0], item[1], item[2]/tf_sum) for item in tfidf_list]\n",
    "#     # tfidf_std_list = [(item[0], item[1], item[1]/count) for item in tfidf_list]\n",
    "\n",
    "#     urls_tfidf_dict[device] = tfidf_std_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_forest_all = {}\n",
    "\n",
    "for device in urls_tfidf_dict.keys():\n",
    "    #每一个设备一个森林\n",
    "    if device not in list(url_forest_all.keys()):\n",
    "        url_forest_all[device] = {'count_all':0}\n",
    "    \n",
    "    for url_tuple in urls_tfidf_dict[device]:\n",
    "        #设备森林计数\n",
    "        url_forest_all[device]['count_all'] += url_tuple[1]\n",
    "        #二级域名\n",
    "        sld = '.'.join(url_tuple[0].split('.')[-2:])\n",
    "        if sld not in list(url_forest_all[device]):\n",
    "            #新建一棵树\n",
    "            url_forest_all[device][sld] = {}\n",
    "            url_forest_all[device][sld]['count'] = 0 # url_tuple[1]\n",
    "            url_forest_all[device][sld]['count_all_accm'] = 0 #url_tuple[1]\n",
    "            url_forest_all[device][sld]['count_all'] = 0\n",
    "            url_forest_all[device][sld]['urls'] = []\n",
    "            \n",
    "            # url_forest_all[device][sld]['children'] = {}\n",
    "        # else:\n",
    "        #     #树已存在,添加计数\n",
    "\n",
    "        url_forest_all[device][sld]['count_all'] += url_tuple[1]\n",
    "        url_forest_all[device][sld]['count_all_accm'] += url_tuple[1]\n",
    "        #多级域名\n",
    "        mlds = url_tuple[0].split('.')\n",
    "        if len(mlds) <= 2:\n",
    "            url_forest_all[device][sld]['count'] += url_tuple[1]\n",
    "            url_forest_all[device][sld]['tfidf'] = url_tuple[2]\n",
    "            if url_tuple[0] not in url_forest_all[device][sld]['urls']:\n",
    "                url_forest_all[device][sld]['urls'].append(url_tuple[0])\n",
    "            continue\n",
    "        mlds.reverse()\n",
    "        mlds = mlds[2:]\n",
    "\n",
    "        current_node = url_forest_all[device][sld]\n",
    "        #构建孩子结点\n",
    "        for mld in mlds:\n",
    "            #孩子结点不存在\n",
    "            if mld not in list(current_node.keys()):\n",
    "                current_node[mld] = {}\n",
    "                current_node[mld]['count'] = 0 # url_tuple[1]\n",
    "                current_node[mld]['count_all_accm'] = 0 # url_tuple[1]\n",
    "            # else:\n",
    "            #     #孩子结点存在，添加计数\n",
    "            current_node[mld]['count_all_accm'] += url_tuple[1]\n",
    "            current_node = current_node[mld]\n",
    "        current_node['count'] += url_tuple[1]\n",
    "        # current_node['count_all_accm'] += url_tuple[1]\n",
    "        current_node['tfidf'] = url_tuple[2]\n",
    "        if url_tuple[0] not in url_forest_all[device][sld]['urls']:\n",
    "            url_forest_all[device][sld]['urls'].append(url_tuple[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_var_aug(tree):\n",
    "    #树权重更新\n",
    "    # tree = url_forest_all['vivoV1816A']['com.cn']\n",
    "\n",
    "    url_leaves = tree['urls']\n",
    "    path_all_list = []\n",
    "\n",
    "    #遍历每个url\n",
    "    for url in url_leaves:\n",
    "        sld = '.'.join(url.split('.')[-2:])\n",
    "        mlds = url.split('.')\n",
    "        mlds.reverse()\n",
    "        mlds = mlds[2:]\n",
    "        url_ld_list = [sld]\n",
    "        url_ld_list.extend(mlds)\n",
    "\n",
    "        #遍历每一个子域名\n",
    "        path_per_list = [tree['count_all_accm']]\n",
    "        current_node = tree\n",
    "        for current_mld in url_ld_list[1:]:\n",
    "            path_per_list.append(current_node[current_mld]['count_all_accm'])\n",
    "            current_node = current_node[current_mld]\n",
    "        path_all_list.append(path_per_list)\n",
    "        # print(path_per_list)\n",
    "        # print(url)\n",
    "\n",
    "    #计算path的前后差值\n",
    "    path_aug_list = []\n",
    "    path_aug_times_list = []\n",
    "    for path in path_all_list:\n",
    "        tmp = []\n",
    "        tmp_times = 1\n",
    "        for i in range(len(path)-1):\n",
    "            tmp.append(path[i]/path[i+1])\n",
    "        for i in range(len(tmp)-1):\n",
    "            tmp_times = tmp_times* tmp[i] * tmp[i+1]\n",
    "        path_aug_times_list.append(math.log(tmp_times)+1)\n",
    "        path_aug_list.append(tmp)\n",
    "\n",
    "    aug_var = math.log(np.array(path_aug_times_list).sum())  + 1# prevent timing zero\n",
    "    tree['aug_var'] = aug_var\n",
    "    # print(tree)\n",
    "    return tree\n",
    "\n",
    "rej_list = ['count','count_all','count_all_accm','aug_var','major']\n",
    "devices = list(url_forest_all.keys())\n",
    "for device in devices:\n",
    "    # print(device)\n",
    "    for tree_name in url_forest_all[device]:\n",
    "        # print(url_forest_all[device][tree_name])\n",
    "        if tree_name in rej_list:\n",
    "            \n",
    "            continue\n",
    "        url_forest_all[device][tree_name] = tree_var_aug(url_forest_all[device][tree_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aug_var更新count后，更新tfidf\n",
    "rej_list = ['count','count_all','count_all_accm','aug_var','major']\n",
    "devices = list(url_forest_all.keys())\n",
    "url_forest_all_device_regen_all = {}\n",
    "for device in devices:\n",
    "    \n",
    "    url_forest_all_device_regen = url_forest_all[device].copy()\n",
    "\n",
    "    for tree_name in url_forest_all[device]:\n",
    "        if tree_name in rej_list:\n",
    "            continue\n",
    "        url_leaves = url_forest_all_device_regen[tree_name]['urls']\n",
    "\n",
    "        #遍历每个url\n",
    "        url_forest_all_device_regen[tree_name]['url_to_count_aug_tfidf'] = {}\n",
    "        url_forest_all_device_regen[tree_name]['count_all_for_aug_tfidf'] = 0.0\n",
    "        for url in url_leaves:\n",
    "            sld = '.'.join(url.split('.')[-2:])\n",
    "            mlds = url.split('.')\n",
    "            mlds.reverse()\n",
    "            mlds = mlds[2:]\n",
    "            url_ld_list = [sld]\n",
    "            url_ld_list.extend(mlds)\n",
    "\n",
    "            #遍历每一个子域名\n",
    "            current_node = url_forest_all_device_regen[tree_name]\n",
    "            for current_mld in url_ld_list[1:]:\n",
    "                current_node = current_node[current_mld]\n",
    "            current_node['count'] = current_node['count']*url_forest_all_device_regen[tree_name]['aug_var']\n",
    "            url_forest_all_device_regen[tree_name]['url_to_count_aug_tfidf'][url] = current_node['count']\n",
    "            url_forest_all_device_regen[tree_name]['count_all_for_aug_tfidf'] += current_node['count']\n",
    "\n",
    "    url_forest_all_device_regen_all[device] = url_forest_all_device_regen\n",
    "\n",
    "#TF IDF\n",
    "import math\n",
    "urls_sta = {}\n",
    "count_device_dict = {} # device: url count after aug\n",
    "for device in devices:\n",
    "    count_device_dict[device] = 0\n",
    "    for tree_name in url_forest_all_device_regen_all[device]:\n",
    "        if tree_name in rej_list:\n",
    "            continue\n",
    "        count_device_dict[device] += url_forest_all_device_regen_all[device][tree_name]['count_all_for_aug_tfidf']\n",
    "        for url in url_forest_all_device_regen_all[device][tree_name]['url_to_count_aug_tfidf']:\n",
    "            if url not in urls_sta:\n",
    "                urls_sta[url] = 0.0 \n",
    "            urls_sta[url] += url_forest_all_device_regen_all[device][tree_name]['url_to_count_aug_tfidf'][url]\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.e ** -(x-20))\n",
    "#对比每条url在别的device中出现的次数，遍历取最小值作为idf\n",
    "tfidf_val_for_std_dict = {} #归一化dict device:val_all\n",
    "for device in devices:\n",
    "    tfidf_val_for_std_dict[device] = 0.0\n",
    "    for tree_name in url_forest_all_device_regen_all[device]:\n",
    "        if tree_name in rej_list:\n",
    "            continue\n",
    "        url_forest_all_device_regen_all[device][tree_name]['url_to_tfidf_aug_min'] = {}\n",
    "        for url in url_forest_all_device_regen_all[device][tree_name]['urls']:\n",
    "            url_count_current_device = url\n",
    "            url_count_current_device_count = url_forest_all_device_regen_all[device][tree_name]['url_to_count_aug_tfidf'][url]\n",
    "\n",
    "            idf_list = []\n",
    "            sld = '.'.join(url_count_current_device.split('.')[-2:])\n",
    "            for device_other in devices:\n",
    "                if device == device_other:\n",
    "                    continue\n",
    "                if sld in url_forest_all_device_regen_all[device_other]:\n",
    "                    if url_count_current_device in url_forest_all_device_regen_all[device_other][sld]:\n",
    "                        url_count_other_device_count = url_forest_all_device_regen_all[device_other][sld][url_count_current_device]\n",
    "                    else:\n",
    "                        url_count_other_device_count = 1 # prevent zero\n",
    "                else:\n",
    "                    url_count_other_device_count = 1 # prevent zero\n",
    "                idf = url_count_current_device_count / url_count_other_device_count\n",
    "                idf_list.append(idf)\n",
    "            min_idf = sigmoid(np.array(idf_list).min())\n",
    "\n",
    "            #计算每条url的tf-idf\n",
    "            tfidf = min_idf * (url_count_current_device_count / count_device_dict[device])\n",
    "            url_forest_all_device_regen_all[device][tree_name]['url_to_tfidf_aug_min'][url_count_current_device] = tfidf\n",
    "            tfidf_val_for_std_dict[device] += tfidf\n",
    "\n",
    "#标准化归一化\n",
    "for device in devices:\n",
    "    for tree_name in url_forest_all_device_regen_all[device]:\n",
    "        if tree_name in rej_list:\n",
    "            continue\n",
    "        \n",
    "        for url in url_forest_all_device_regen_all[device][tree_name]['url_to_tfidf_aug_min']:\n",
    "            url_forest_all_device_regen_all[device][tree_name]['url_to_tfidf_aug_min'][url] = url_forest_all_device_regen_all[device][tree_name]['url_to_tfidf_aug_min'][url] / tfidf_val_for_std_dict[device]\n",
    "            \n",
    "                \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计每个device森林里的major树\n",
    "rej_list = ['count','count_all','count_all_accm','aug_var','major']\n",
    "for device in devices:\n",
    "    major_value = 0\n",
    "    url_forest_all_device_regen_all[device]['major'] = 0\n",
    "    trees = url_forest_all_device_regen_all[device]\n",
    "    for tree_name in trees:\n",
    "        if tree_name in rej_list:\n",
    "            continue\n",
    "        if len(list(url_forest_all_device_regen_all[device][tree_name]['url_to_tfidf_aug_min'].keys())) > major_value:\n",
    "            major_value = len(list(url_forest_all_device_regen_all[device][tree_name]['url_to_tfidf_aug_min'].keys()))\n",
    "            url_forest_all_device_regen_all[device]['major'] = tree_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "from scapy.all import *\n",
    "from scapy.utils import PcapReader\n",
    "import os\n",
    "from subprocess import Popen, PIPE\n",
    "from collections import Counter\n",
    "\n",
    "def url_digger(file):\n",
    "\n",
    "    def get_sec(item):\n",
    "        return item[1]\n",
    "    def get_fir(item):\n",
    "        return item[0]\n",
    "    \n",
    "    def url_d(url):\n",
    "        top_url = ['top','com','xyz','xin','vip','com','net','org','gov','edu','biz','name','info','mobi','pro','travel','club','museum','post','rec','asia','cc','cn','gov','info','net','nom','org','rec','store','web','io','local']\n",
    "        # print(url)\n",
    "        if url[-1] == '.':\n",
    "            url = url[:-1]\n",
    "        if url.split('.')[-1] in top_url:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def Find(string): \n",
    "        url = re.findall('(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', string)\n",
    "        return [item  for item in url if len(item.split('.')) >=2]\n",
    "        \n",
    "    packets=rdpcap(file)\n",
    "    urls_all = []\n",
    "    for pkt in packets:\n",
    "        # print(pkt)\n",
    "        pkt = str(pkt).replace('\"', '')\n",
    "#         pkt = pkt.replace('\\\\', '')\n",
    "        url_per_pkt = [item for item in Find(pkt) if url_d(item)]\n",
    "        tmp = []\n",
    "        for item in url_per_pkt:\n",
    "            if item[-1] == '.':\n",
    "                tmp.append(item[:-1])\n",
    "            else:\n",
    "                tmp.append(item)\n",
    "        if len(tmp) != 0 :\n",
    "            urls_all.extend(tmp)\n",
    "        # print(urls_all)\n",
    "        # print(Find(pkt))\n",
    "    # urls_all = sorted(urls_all, key=get_sec,reverse=True)\n",
    "\n",
    "    return urls_all\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### npy version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background\n",
      "Xiaomi:Xiaomi2s\n",
      "Xiaomi:Xiaomi2s\n",
      "Xiaomi:Xiaomi2s\n",
      "277 / 2776\n",
      "554 / 2776\n",
      "Xiaomi:Xiaomi2s\n",
      "831 / 2776\n",
      "Xiaomi:Xiaomi2s\n",
      "1108 / 2776\n",
      "1385 / 2776\n",
      "Xiaomi:Xiaomi2s\n",
      "1662 / 2776\n",
      "1939 / 2776\n",
      "2216 / 2776\n",
      "2493 / 2776\n",
      "Xiaomi:Xiaomi2s\n",
      "2770 / 2776\n"
     ]
    }
   ],
   "source": [
    "#测试函数\n",
    "import numpy as np\n",
    "\n",
    "#权重更新的验证函数\n",
    "def match_per_pcap_update_val(urls_test_w, url_forest_all):\n",
    "    #extract urls\n",
    "    # print(urls_test_w)\n",
    "\n",
    "    #matching\n",
    "    devices =  list(url_forest_all.keys()) #['SumsungC5']#\n",
    "    devices_value_dict = {}\n",
    "    for device in devices:\n",
    "        #提取森林里所有url\n",
    "        url_val_all = {}\n",
    "        for tree_name in url_forest_all[device]:\n",
    "            if tree_name in rej_list:\n",
    "                continue\n",
    "            for url in url_forest_all[device][tree_name]['url_to_tfidf_aug_min']:\n",
    "                url_val_all[url] = url_forest_all[device][tree_name]['url_to_tfidf_aug_min'][url]\n",
    "        \n",
    "        #查询url\n",
    "        devices_value_dict[device] = [] #{device : []}\n",
    "\n",
    "\n",
    "        for tuple_per in urls_test_w:\n",
    "\n",
    "            if tuple_per[0] in url_val_all:\n",
    "                devices_value_dict[device].append(url_val_all[tuple_per[0]])\n",
    "            \n",
    "            \n",
    "    return devices_value_dict\n",
    "\n",
    "#加入cover的权重更新的验证函数\n",
    "def match_per_pcap_update_val_with_cover_tree(urls_test_w, url_forest_all,th):\n",
    "\n",
    "    #matching\n",
    "    devices =  list(url_forest_all.keys()) #['SumsungC5']#\n",
    "    devices_value_dict = {}\n",
    "    for device in devices:\n",
    "        #提取森林里所有url\n",
    "        url_val_all = {}\n",
    "        for tree_name in url_forest_all[device]:\n",
    "            if tree_name in rej_list:\n",
    "                continue\n",
    "            for url in url_forest_all[device][tree_name]['url_to_tfidf_aug_min']:\n",
    "                url_val_all[url] = url_forest_all[device][tree_name]['url_to_tfidf_aug_min'][url]\n",
    "        \n",
    "        #查询url\n",
    "        devices_value_dict[device] = [] #{device : []}\n",
    "\n",
    "        #计算每棵树的覆盖率\n",
    "        devices_cover_dict = {} #{device : {Tree1 : [], Tree2: []}}\n",
    "\n",
    "\n",
    "        for tuple_per in urls_test_w:\n",
    "            if tuple_per[0] in url_val_all:\n",
    "                sld = '.'.join(tuple_per[0].split('.')[-2:])\n",
    "                \n",
    "                if sld not in devices_cover_dict.keys():\n",
    "                    devices_cover_dict[sld] = []\n",
    "                \n",
    "                devices_cover_dict[sld].append(url_val_all[tuple_per[0]])\n",
    "\n",
    "        #判断cover是否满足阈值\n",
    "        for sld in devices_cover_dict:\n",
    "            tree_all_value = np.array(list(url_forest_all[device][sld]['url_to_tfidf_aug_min'].values())).sum()\n",
    "            if np.array(devices_cover_dict[sld]).sum()/ tree_all_value>= th:\n",
    "                devices_value_dict[device].append(tree_all_value)\n",
    "            else:\n",
    "                devices_value_dict[device].extend(devices_cover_dict[sld])\n",
    "\n",
    "                      \n",
    "    return devices_value_dict\n",
    "\n",
    "#加入major树的权重更新的验证函数\n",
    "def match_per_pcap_update_val_with_major_tree(urls_test_w, url_forest_all, th = 0.5):\n",
    "\n",
    "    #matching\n",
    "    devices =  list(url_forest_all.keys()) #['SumsungC5']#\n",
    "    devices_value_dict = {}\n",
    "    for device in devices:\n",
    "        #提取森林里所有url\n",
    "        url_val_all = {}\n",
    "        for tree_name in url_forest_all[device]:\n",
    "            if tree_name in rej_list:\n",
    "                continue\n",
    "            for url in url_forest_all[device][tree_name]['url_to_tfidf_aug_min']:\n",
    "                url_val_all[url] = url_forest_all[device][tree_name]['url_to_tfidf_aug_min'][url]\n",
    "        \n",
    "        #查询url\n",
    "        devices_value_dict[device] = [] #{device : []}\n",
    "\n",
    "        major_matched = False\n",
    "\n",
    "        for tuple_per in urls_test_w:\n",
    "\n",
    "            if tuple_per[0] in url_val_all:\n",
    "                sld = '.'.join(tuple_per[0].split('.')[-2:])\n",
    "                if sld == url_forest_all[device]['major']:\n",
    "                    if not major_matched:\n",
    "                        devices_value_dict[device].append(np.array(list(url_forest_all[device][sld]['url_to_tfidf_aug_min'].values())).sum())\n",
    "                        major_matched = True\n",
    "                else:\n",
    "                    devices_value_dict[device].append(url_val_all[tuple_per[0]])\n",
    "            \n",
    "            \n",
    "    return devices_value_dict\n",
    "\n",
    "def cal_value_per_pcap(devices_value_dict):\n",
    "    def getsec(item):\n",
    "        return item[1]\n",
    "    value_tuple_list = []\n",
    "    #sum up each list\n",
    "    for device in list(devices_value_dict.keys()):\n",
    "        value_tuple_list.append((device, np.array(devices_value_dict[device]).sum()))\n",
    "    value_tuple_list = sorted(value_tuple_list, key= getsec, reverse= True)\n",
    "\n",
    "    return value_tuple_list\n",
    "\n",
    "def clf_per_pcap(value_tuple_list, th = 0.0, level = \"Model\"):\n",
    "    if level == \"Model\":\n",
    "        if value_tuple_list[0][1] >= th:\n",
    "            print(value_tuple_list[0][0])\n",
    "            return 1,value_tuple_list[0][0]\n",
    "        else:\n",
    "\n",
    "            return 0,value_tuple_list[0][0]\n",
    "    elif level == \"Brand\":\n",
    "        if value_tuple_list[0][1] >= th:\n",
    "            print(value_tuple_list[0][0])\n",
    "            return 1,value_tuple_list[0][0]\n",
    "        else:\n",
    "\n",
    "            return 0,value_tuple_list[0][0]\n",
    "    \n",
    "\n",
    "\n",
    "urls_dict = np.load(\"./features_bg_15s.npy\", allow_pickle=True).item() \n",
    "res_dict = {}\n",
    "miss_dict = {}\n",
    "for label in urls_dict:\n",
    "    print(label)\n",
    "    \n",
    "    jud_list = []\n",
    "    miss_list = []\n",
    "        \n",
    "    count = 1 \n",
    "\n",
    "    for urls_test_w in urls_dict[label]:\n",
    "        # devices_value_dict = match_per_pcap_update_val(urls_test_w, url_forest_all_device_regen_all)\n",
    "        devices_value_dict = match_per_pcap_update_val_with_cover_tree(urls_test_w, url_forest_all_device_regen_all, th = 0.6)\n",
    "\n",
    "        value_tuple_list = cal_value_per_pcap(devices_value_dict) \n",
    "\n",
    "        jud, pred = clf_per_pcap(value_tuple_list, label, th = 0.7, level = \"Model\") #Brand or Model level\n",
    "        jud_list.append(jud)\n",
    "\n",
    "        if jud == 0:\n",
    "            miss_list.append(pred)\n",
    "\n",
    "            \n",
    "            \n",
    "        if count % int(len(urls_dict[label]) / 10) == 0:\n",
    "            print(\"{} / {}\".format(count, len(urls_dict[label])))\n",
    "        count += 1\n",
    "\n",
    "    miss_dict[label] = miss_list\n",
    "    res_dict[label] = jud_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background : 0.002521613832853026\n",
      "Overall_ACC : 0.002521613832853026\n"
     ]
    }
   ],
   "source": [
    "acc_all = 0.0\n",
    "all = 0.0\n",
    "for models in res_dict:\n",
    "    acc = np.array(res_dict[models]).sum()/len(res_dict[models])\n",
    "    acc_all += np.array(res_dict[models]).sum()\n",
    "    all += len(res_dict[models])\n",
    "    print(\"{} : {}\".format(models,acc))\n",
    "print(\"{} : {}\".format(\"Overall_ACC\",acc_all/all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
